## Extracting Meaning from Strings

- Use `str_detect()` to search for keywords like “love” in track names  
- Use `str_length()` and `str_count()` to quantify text patterns  
- Convert strings to lowercase for consistent matching  
- Summarize counts across groups with `group_by()` and `summarize()`

::: {.notes}
*Why this matters*  
Text data often contains meaningful patterns—titles, names, and labels can reflect themes or group structure. You need string tools to analyze them effectively.

*What you'll do*  
You’ll detect keywords in titles, count characters or words, and group results by genre to reveal trends. This shows how string functions turn messy text into structured insights.
:::

---

## Cleaning Up Track Titles with Regex

- Use `str_remove_all()` to strip out parentheses and featured credits  
- Use regular expressions like `"\\(.*?\\)"` for non-greedy matching  
- Extract phrases with `str_extract()` and clean them with `str_replace_all()`  
- Get cleaner track names for visualizations and summaries

::: {.notes}
*Why use regex?*  
Many track titles include extra text like “(Remix)” or “(feat. Artist)” that can clutter analysis. Regex helps you clean and isolate what's important.

*What you’ll learn*  
You’ll remove or extract parenthetical text, especially to clean labels or find featured artists. These string-cleaning tasks are essential for tidy summaries and clean plots.
:::

---

## Working with Artists and Categorical Variables

- Use `separate_rows()` to split multi-artist entries into long format  
- Count artist appearances and identify those crossing genres  
- Use `fct_lump()` to group rare categories into “Other”  
- Use `fct_relevel()` to control the order of factor levels

::: {.notes}
*Why this matters*  
Many tracks feature multiple artists, and many categories have long tails. Tidying this up improves your summaries and plots.

*What you’ll do*  
You’ll tidy the `artists` column for more accurate counts, then lump less frequent genres or reorder categorical levels to improve clarity in visualization.
:::

---

## Parsing Dates and Grouping by Time

- Use `make_date()` to construct full dates from parts  
- Use `floor_date()` to create time bins (e.g. every 6 hours)  
- Extract month or weekday labels with `month()` and `wday()`  
- Group and summarize by date-time intervals

::: {.notes}
*Why work with dates?*  
Time variables are central to many datasets, from weather to flight delays. You need to aggregate and interpret trends over time.

*What you’ll learn*  
You’ll build full date columns from components and group them into meaningful time buckets (like hourly or daily bins). This allows for smoother time-based summaries and interactive plots.
:::

---

## Visualizing Categorical Preferences and Trends

- Use `count()` with `group_by()` to tabulate responses by category  
- Reorder with `fct_infreq()` to sort by most common responses  
- Collapse rare entries with `fct_lump()`  
- Use `geom_col(position = "dodge")` to compare group counts

::: {.notes}
*Why it matters*  
Whether you're analyzing genres, weather apps, or survey responses, categorical preferences matter. You want to present them clearly.

*What you'll do*  
You’ll tally responses by region and weather app, sort by frequency, and show differences using a side-by-side bar chart. This brings together factor handling and `ggplot2` for impactful communication.
:::

---
